# global parameters
global_parameters:
  # model related
  - &model_arch_type 'TransformersModel'
  - &is_train true                  # [true,false] # 如果不使用transformers model，该参数表示是否训练词向量，如果使用transformers model，该参数表示是否对transformers model 进行微调
  - &class_num 6
  # data related
  - &dataset_type 'MedicalDataset'
  - &data_dir 'data/medical_question/train_valid_query' # 定义锚
  - &cache_dir 'data/medical_question/.cache'
  - &overwrite_cache false
  - &transformer_model 'clue/albert_chinese_tiny' # 详情参见： https://huggingface.co/models ['clue/albert_chinese_tiny','hfl/chinese-bert-wwm']
  - &shuffle true
  - &force_download false
  - &num_workers 4
  - &batch_size 8


experiment_name: *model_arch_type
num_gpu: 2                         # GPU数量
device_id: '0,1'
visual_device: '0,1'
main_device_id: '0'
resume_path: null                         # path to latest checkpoint

# 模型
model_arch:
  type: *model_arch_type
  args:
    transformer_model: *transformer_model
    cache_dir: *cache_dir
    force_download: *force_download
    is_train: *is_train
    class_num: *class_num

train_set:
  type: *dataset_type
  args:
    data_dir: *data_dir
    file_name: 'medical_train.jsonl'
    cache_dir: *cache_dir
    overwrite_cache: *overwrite_cache
    transformer_model: *transformer_model
    force_download: *force_download
    shuffle: *shuffle
    batch_size: *batch_size   # data loader batch size
    num_workers: *num_workers # data loader num of worker

valid_set:
  type: *dataset_type
  args:
    data_dir: *data_dir
    file_name: 'medical_valid.jsonl'
    cache_dir: *cache_dir
    overwrite_cache: *overwrite_cache
    transformer_model: *transformer_model
    force_download: *force_download
    shuffle: *shuffle
    batch_size: *batch_size   # data loader batch size
    num_workers: *num_workers # data loader num of worker

query_set:
  type: *dataset_type
  args:
    data_dir: *data_dir
    file_name: 'medical_query.jsonl'
    cache_dir: *cache_dir
    overwrite_cache: *overwrite_cache
    transformer_model: *transformer_model
    force_download: *force_download
    shuffle: *shuffle
    batch_size: *batch_size   # data loader batch size
    num_workers: *num_workers # data loader num of worker



optimizer:
  type: 'Adam'
  args:
    lr: 0.001


loss:
  - "binary_loss"

metrics:
  - 'macro_f1'
  - 'micro_f1'
  - 'sample_f1'

active_learning:
  query_num: null  # 每个epoch在查询集采样query_num个样本进行预测, 如果 query_num:null 则采样整个查询集
  # 查询策略 [random_sampling,multilabel_margin_sampling,margin_sampling,entropy_sampling]
  type: 'multilabel_margin_sampling'
  args:
    top_n: 50   # 对查询样本中的多少个样本进行标注

trainer:
  epochs: 1000
  save_dir: 'saved/'
  save_period: 1
  verbosity: 2
  monitor: "max val_macro_f1"
  early_stop: 5
  tensorboard: true

